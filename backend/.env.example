# backend/.env.example
PORT=4000
FRONTEND_ORIGIN=http://localhost:5173

# LLM
LLM_API_KEY=your_api_key_here
LLM_API_URL=https://api.openai.com/v1/chat/completions

# Limits
MAX_UPLOAD_MB=10